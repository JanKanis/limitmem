#!/bin/sh

# strict mode: error if commands fail or if unset variables are used
set -eu

limit=''
swaplimit="1G"
snap=0
debug=0

while true
do
	# parse command line args and find limits

	if [ "$#" -lt 1 -o "$1" = "-h" -o "$1" = "--help" ]
	then
		echo Usage: `basename "$0"` "[--snap] <limit> <command>..."
		echo or: `basename "$0"` "[--snap] <memlimit> -s <swaplimit> <command>..."
		echo
		echo Pass "--snap" if the command is a Snap app, which will place itself into a systemd scope
		exit 1
	fi

	if [ "$1" = "-s" ]
	then
		shift
		swaplimit="$1"
		shift
		continue
	fi

	if [ "$1" = "--snap" ]
	then
		shift
		snap=1
		continue
	fi

	if [ "$1" = "--debug" ]
	then
		shift
		debug=1
		continue
	fi

	if [ "$1" = -- ]
	then
		shift
		break
	fi

	if [ "$limit" = "" ]
	then
		limit="$1"
		shift
		continue
	fi

	break  # Reached start of command
done

if [ "$debug" = 1 ]
then
	echo limit: $limit
	echo swaplimit: $swaplimit
	echo snap: $snap
fi

if [ "$snap" = 0 ]
then
	exec systemd-run --user --scope --expand-environment=no \
			-p MemoryMax="$limit" -p MemorySwapMax="$swaplimit" fish -c "
		set -l cgroup_path (string split -f3 -m2 : (grep 0:: /proc/self/cgroup))
		set -U JCLIMITMEM \$JCLIMITMEM (basename \"$1\"):\$cgroup_path
		command \$argv
		set -l max_count (grep max /sys/fs/cgroup\$cgroup_path/memory.events | cut -f2 -d\  )
		set -l oom_kill_count (grep oom_kill /sys/fs/cgroup\$cgroup_path/memory.events | cut -f2 -d\  )
		if [ \$max_count != 0 ]
			echo \"***Memory limit reached \$max_count times***\"
		end
		if [ \$oom_kill_count != 0 ]
			echo \"***OOM killer was triggered \$oom_kill_count times***\"
		end" -- "$@"
else
	cmd_basename=$(basename "$1")
	scopename_pattern=snap.$cmd_basename.\*
	if [ -e /sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/app.slice/$scopename_pattern ]
	then
		echo "Error: A snap for '$cmd_basename' is already running. Running a second instance is currently not supported in $(basename "$0"). Details:"
		systemctl --user --no-pager status -l "$scopename_pattern"
		exit 1
	fi

	# Start a background subshell to monitor the cgroup stats
	(
		get_scope() {
			systemctl --user list-units --type=scope --no-legend --plain "$scopename_pattern" | head -1 | awk '{print $1}'
		}

		# We need to wait a moment for the snap cgroup to be started. Usually 200 ms is enough.
		# There is a race condition here though. If the cgroup already finishes before we can
		# start monitoring it we will miss any stats.
		sleep 0.2;
		# But sometimes starting the snap can take significant time, so wait some more.
		scopename=$(get_scope)
		if [ -z "$scopename" ]
		then
			echo sleeping some more
			sleep 1
			scopename=$(get_scope)
		fi
		if [ -z "$scopename" ]
		then
			echo sleeping some more
			sleep 7
			scopename=$(get_scope)
		fi
		if [ -z "$scopename" ]
		then
			echo "Error: unable to find snap cgroup, no stats available"
			exit
		fi
		cgroup_path="/user.slice/user-1000.slice/user@1000.service/app.slice/$scopename"
		echo scope name found: $scopename

		# Add to JCLIMITMEM fish universal variable for the jcusage script
		fish -c "set -U JCLIMITMEM \$JCLIMITMEM \"$cmd_basename:$cgroup_path\""

		# Assume the snap has been started by now. If not, we will just exit without any stats.
		systemctl set-property --user "$scopename" MemoryMax="$limit" MemorySwapMax="$swaplimit";
		limitmem_msg='Cgroup exited, no stats collected'
		last_print=0
		# Ideally we would wait for the delete_self event (in addition to modify). But that isn't generated when
		# the cgroup exits. What is generated is an open,access,close_nowrite sequence. I'm not sure what process
		# does that or if the kernel cgroup code itself generates that, but at least it allows us to exit when the
		# cgroup closes by also monitoring for the close event.
		while inotifywait -qq -e modify -e delete_self -e close /sys/fs/cgroup$cgroup_path/memory.events 2>/dev/null
		do
			stats=$(cat /sys/fs/cgroup$cgroup_path/memory.events 2>/dev/null)
			if [ "$stats" = "" ]
			then
				break
			fi
			#cat /sys/fs/cgroup$cgroup_path/memory.events
			max_count=$(echo "$stats" | grep max | cut -f2 -d\  )
			oom_kill_count=$(echo "$stats" | grep oom_kill | cut -f2 -d\  )
			if [ $(expr "$last_print" + 2) -le $(date +%s) ]
			then
				date "+%d %h %H:%M:%S: Limit reached $max_count times"
				last_print=$(date +%s)
			fi
			limitmem_msg=''
			if [ "$max_count" != 0 ]
			then
				limitmem_msg="***Memory limit reached $max_count times***"
			fi
			if [ "$oom_kill_count" != 0 ]
			then
				limitmem_msg="$limitmem_msg\n***OOM killer was triggered $oom_kill_count times***"
			fi
		done
		echo $limitmem_msg
	)&
	command "$@"
	# Bug: if the systemd scope fails due to all processes being killed by the oom-killer, the scope is not deleted but transitions into a 'failed' state, where its cgroup remains without any processes. In that case the stats collection subshell keeps hanging waiting for the cgroup to exit.
	wait  # Wait for background stats collection subshell to finish

fi


